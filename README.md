# [Project 1: Focusing on cleaning and visulisation using R](https://github.com/robertmash/intro_to_data_science)
- used packages: Tidyvserse, ggplot2, janitor, here, and lubridate.
- Uses data from Nasa and GOV.uk, I've linked these below. 
- Visualise trends and statistics based of climate change, and rates of stops and searches throughout my investigation.
- I find that In 2017, we can denote that black people were up to 8 times more likely to be stopped in comparison to white people. This is similar with the Asian population who are increasingly more likely to be stopped over white individuals. I didn't include the "Other" variable as it was missing some data, which wouldnt add any impact to the conclusion. 

## Visualisations after cleaning:

![](https://github.com/robertmash/Projects/blob/main/images/visualisations.png)


### [Data used in this investigation](https://github.com/robertmash/intro_to_data_science/tree/main/data)

# [Project 2: Statistical Methods and Data Analysis](https://github.com/robertmash/stats_project)
- Firstly cleaning the datasets and collecting summary stats about each variable. 
- We look at 3 main datasets, car data, comicbook characters and premier league players.
- Also look at 'Salaries' dataset within R, which illistrates the 
- Implementing statistical analysis on a multitude of datasets to derive statistically significant results
- Using linear, multi-linear and logistic regression methods. 
- Plotting confidence intervals & checking for normality. 
- Plotting ROC, interpretting the AUC. Graphing my findings, showing both sensitivity and specificity values. 
- Creating a GLM for the 'divisionWinners' of our baseball dataset. This is then split into a test and training set, to graph the ROC and a confusion matrix comparing the full and reduced model. 

## Statistical visualisations (ROC, log10 relationships, Residual vs Leverage and Specificity & Sensitivity, Confidence Intervals):

![](https://github.com/robertmash/robertmash_portfolio/blob/main/images/statistical_graphs.png)

### [Data used in this investigation](https://github.com/robertmash/stats_project/tree/main/data)

# [Project 3: Student Database Project](https://github.com/robertmash/StudentDatabase_Project/blob/main/programming%20for%20ds/CW1/CW1.ipynb)
- Project is split into two sections. 
- First section focusing is on data-preprocessing, creating functions to clean and ready the data to be worked on. This involves:
- Standardising, normalising, removing duplicates and creating an SQL database for these results. 

## [Section 2:](https://github.com/robertmash/StudentDatabase_Project/tree/main/programming%20for%20ds/cw2)
- Second part of the project involves using the SQL database to create export the database and creating subsets for the students.
- This involves identifying which students are hardworking i.e. scored > 60 in all tests
- Highlighting underperfoming students i.e. scored < 60 in all tests.
- Addittionally, I create a GUI section of the programme so when the user inputs a student ID, they their overall performance back to them. 

# [Project 4: Data Mining Project](https://github.com/robertmash/DataMining_Project)
- Using Weka to produce a report focusing on the implementation of machine learning methods
- I firstly pre-process the dataset. 
- Initalise linear regression and relevant attribute evalutors (OneRule, Relief F)
- Implementation of supervised learning classifiers (Lazy IBk classifer, Naive Bayes)
- Implementation of equal binning, tweaking this parameter for optimised results.
- Finally, using K-means clustering onto the dataset. 



